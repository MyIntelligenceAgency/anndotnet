!you can make a comment into file by starting '!' character

!********mlconfigig*******
mlconfigid:unique-mlconfig-identification

!***************metadata for the dataset

metadata:|Column01:x1;Numeric;Feature;Average;|Column01:x1;Numeric;Feature;Average;|Column01:x1;Numeric;Feature;Average;|Column01:x1;Numeric;Feature;Average; |Column05:Flower;Category;Label;None;setosa;versicolor;virginica


!****Features and Lebels*****
!features labels define features of training data set
!Example of defining features and labels
!features:|[featurename1] [dimension] [hasdynamicaxes] [isSparsedata]	|[featurename2] [dimension] [hasdynamicaxes] [isSparsedata] ...
!labels:|[labename1] [dimension] [hasdynamicaxes] [isSparsedata]	|[labename2] [dimension] [hasdynamicaxes] [isSparsedata] ...

features:|features 4 0
labels:|labels 3 0

!*********Network Model******
!set of separated Names:values for nn creation
! all keys are mandatory
! Type - type of the nn nework can be one of (FeedForward, DeepFF, LSTMRecurrent, EmbeddedLSTM)
! HLayers  - number of hidden layers in Deep network
! HDimensions - number of neurons in each hidden layer,  (Example: |HDimensions:10 45 20; |HDimensions:5)
! HActivation: - activation function of hidden layers (tanh, sigmoid, relu, ...)
! OActivation: - activation function for output dense layer (tanh, sigmoid, relu, ...)
! HLSTM - number of layers in LSTM RNN
! LSTMCell - number of LSTM cells in each hlayer
! EmbeddingDim - output dimension for embedded layer.
! DropRate  - droprate for the DropOut layer (0,1)

network:|Layer:Normalization 0 0 0 None 0 0 |Layer:Dense 5 0 0 ReLU 0 0 |Layer:Dense 3 0 0 Softmax 0 0 


!******Learning Parameters********
!define loss and evaluation function
!loss or evaluation function can be one of defined functions:
! - SquaredError -for regressions
! - ClassificationError - for classification problems
! - BinaryCrossEntropy - Computes the binary cross entropy (aka logistic loss) between the output and target.
! - CrossEntropyWithSoftmax - computes the cross entropy between the target_vector and the softmax of the output_vector
!or one of custom function
! - RMSError - root mean square error
! - MSError - mean squared error

!learning parameters

! supported learners: 
! - MomentumSGDLearner 
! - FSAdaGradLearner
! - AdaGradLearner
! - AdamLearner

!training rates
! - lrate:0.05
! - momentum:0.9


learning:|Type:SGDLearner |LRate:0.01 |Momentum:0 |Loss:CrossEntropyWithSoftmax|Eval:ClassificationAccuracy|L1:0|L2:0


!******* Training Parameters***********
!training process and minibatch
!minibatch:custom
!epoch:10
!batchSize:100
!randomizeBatch:true
!progressFreq:5
!supported 
! - custom  - reader with variable sequence length
! - default - default text format reader minibatch

training:|Type:Default |BatchSize:100 |Epochs:1000 |RandomizeBatch:0 |SaveWhileTraining:1 |FullTrainingSetEval:1 |ProgressFrequency:50 |ContinueTraining:0 |TrainedModel:

!*******************Paths of mconfig files**************************
!the keyword contains 7 parameters with 7 parameter values which represent paths for different components 
!1. ParameterName= Training - relative path to the training dataset
!2. ParameterName= Validation - relative path to the validation dataset 
!3. ParameterName= Test - relative path to the test dataset
!4. ParameterName= TempModels - relative folder path for saving models during training
!5. ParametersName=Models - relative path folder for to save model after training
!6. ParameterName= Result - folder where the results are saved during export 
!7. ParameterName = Log - folder where th etraining history is saved.

paths:|Training:data\iris_with_hot_vector.txt |Validation:data\iris_with_hot_vector_test.txt |Test:data\iris_with_hot_vector_test.txt |TempModels:temp_models |Models:models |Result:FFNModel_result.csv |Logs:log 
